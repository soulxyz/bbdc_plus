"""
OCR è¯†åˆ«å¼•æ“
ä½¿ç”¨ RapidOCR è¯†åˆ«å±å¹•æŒ‡å®šåŒºåŸŸçš„æ–‡å­—
"""

import re
from typing import List, Optional, Tuple
from PIL import ImageGrab, Image
from rapidocr_onnxruntime import RapidOCR
import numpy as np
from dpi_utils import get_dpi_manager
import config


class OCREngine:
    _shared_instance = None

    @classmethod
    def get_shared(cls):
        """è·å–å…±äº«çš„ OCR å®ä¾‹ï¼ˆå•ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰"""
        if cls._shared_instance is None:
            cls._shared_instance = OCREngine()
        return cls._shared_instance
    def __init__(self):
        """åˆå§‹åŒ– OCR å¼•æ“"""
        self.last_recognized_word = None
        self.recognition_count = 0
        
        # è·å– DPI ç®¡ç†å™¨
        self.dpi_manager = get_dpi_manager()
        self._last_image_hash: Optional[int] = None
        
        # åˆå§‹åŒ– RapidOCR
        print("   æ­£åœ¨åŠ è½½ RapidOCR æ¨¡å‹...")
        self.ocr = RapidOCR()
        print("   âœ… RapidOCR åŠ è½½å®Œæˆ")
    
    def capture_region(self, x: int, y: int, width: int, height: int) -> Image.Image:
        """æˆªå–å±å¹•æŒ‡å®šåŒºåŸŸ
        
        Args:
            x: åŒºåŸŸå·¦ä¸Šè§’ X åæ ‡ï¼ˆé€»è¾‘åæ ‡ï¼‰
            y: åŒºåŸŸå·¦ä¸Šè§’ Y åæ ‡ï¼ˆé€»è¾‘åæ ‡ï¼‰
            width: åŒºåŸŸå®½åº¦ï¼ˆé€»è¾‘åæ ‡ï¼‰
            height: åŒºåŸŸé«˜åº¦ï¼ˆé€»è¾‘åæ ‡ï¼‰
        
        Returns:
            PIL Image å¯¹è±¡
        """
        # åº”ç”¨ DPI ç¼©æ”¾ï¼ˆè½¬æ¢ä¸ºç‰©ç†åæ ‡ï¼‰
        scaled_x, scaled_y, scaled_width, scaled_height = self.dpi_manager.scale_coordinates(
            x, y, width, height
        )
        
        # è°ƒè¯•è¾“å‡ºï¼šæ‰“å°é€»è¾‘/ç‰©ç†åæ ‡å¯¹ç…§
        try:
            import config
            if getattr(config, 'DEBUG', False):
                print(f"ğŸ“ OCR æˆªå›¾åæ ‡: é€»è¾‘=({x},{y},{width},{height}) â†’ ç‰©ç†=({scaled_x},{scaled_y},{scaled_width},{scaled_height})")
        except Exception:
            pass
        
        # æˆªå–å±å¹•åŒºåŸŸï¼ˆä½¿ç”¨ç‰©ç†åæ ‡ï¼‰
        bbox = (scaled_x, scaled_y, scaled_x + scaled_width, scaled_y + scaled_height)
        screenshot = ImageGrab.grab(bbox)
        return screenshot
    
    def recognize_text(self, image: Image.Image) -> str:
        """è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—
        
        Args:
            image: PIL Image å¯¹è±¡
        
        Returns:
            è¯†åˆ«å‡ºçš„æ–‡å­—
        """
        try:
            # å¿«é€Ÿé¢„å¤„ç†ï¼šç°åº¦ + ä¸‹é‡‡æ · + äºŒå€¼åŒ–ï¼ˆå†è½¬å›RGBï¼Œå…¼å®¹æ¨¡å‹ï¼‰
            if getattr(config, 'OCR_FAST_MODE', True):
                img = image.convert('L')
                w, h = img.size
                # é™åˆ¶è¾“å…¥å¤§å°å¹¶æŒ‰æ¯”ä¾‹ç¼©æ”¾
                max_w = getattr(config, 'OCR_MAX_WIDTH', 900)
                scale = getattr(config, 'OCR_DOWNSCALE', 0.75)
                target_w = min(int(w * scale), max_w) if w > 0 else w
                if target_w > 0 and target_w < w:
                    target_h = max(1, int(h * target_w / w))
                    img = img.resize((target_w, target_h), Image.BILINEAR)
                # äºŒå€¼åŒ–
                thr = getattr(config, 'OCR_BIN_THRESHOLD', 180)
                img = img.point(lambda p: 255 if p > thr else 0, mode='1')
                # è½¬å›ä¸‰é€šé“
                img = img.convert('RGB')
            else:
                img = image.convert('RGB')

            # è½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆRapidOCR éœ€è¦ï¼‰
            img_array = np.array(img)
            
            # ä½¿ç”¨ RapidOCR è¯†åˆ«
            # result æ ¼å¼: [[[box], text, confidence], ...]
            result, elapse = self.ocr(img_array)
            
            self.recognition_count += 1
            
            # å¦‚æœæ²¡æœ‰è¯†åˆ«ç»“æœ
            if not result:
                return ""
            
            # æå–æ‰€æœ‰è¯†åˆ«åˆ°çš„æ–‡æœ¬ï¼Œç”¨ç©ºæ ¼è¿æ¥
            texts = [item[1] for item in result]
            text = ' '.join(texts)
            
            return text.strip()
        
        except Exception as e:
            print(f"âŒ OCR è¯†åˆ«é”™è¯¯: {e}")
            return ""

    # ---- å›¾åƒå˜åŒ–æ£€æµ‹ ----
    def _compute_ahash(self, image: Image.Image) -> int:
        """è®¡ç®—å›¾åƒçš„ aHashï¼ˆå¹³å‡å“ˆå¸Œï¼‰ï¼Œè¿”å› 64bit æ•´æ•°"""
        img = image.convert('L').resize((8, 8), Image.BILINEAR)
        arr = np.asarray(img, dtype=np.float32)
        mean = arr.mean()
        bits = (arr > mean).astype(np.uint8).flatten()
        value = 0
        for b in bits:
            value = (value << 1) | int(b)
        return int(value)

    def _hamming_distance(self, a: int, b: int) -> int:
        x = a ^ b
        # Brian Kernighan æŠ€å·§
        cnt = 0
        while x:
            x &= x - 1
            cnt += 1
        return cnt
    
    def extract_words(self, text: str) -> List[str]:
        """ä»è¯†åˆ«çš„æ–‡æœ¬ä¸­æå–è‹±æ–‡å•è¯
        
        Args:
            text: è¯†åˆ«å‡ºçš„æ–‡æœ¬
        
        Returns:
            å•è¯åˆ—è¡¨
        """
        print(text)
        if not text:
            return []
        
        # ä½¿ç”¨æ­£åˆ™æå–æ‰€æœ‰è‹±æ–‡å•è¯ï¼ˆè‡³å°‘2ä¸ªå­—æ¯ï¼‰
        words = re.findall(r'\b[a-zA-Z]{2,}\b', text)
        
        # è½¬ä¸ºå°å†™å¹¶å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
        seen = set()
        unique_words = []
        for word in words:
            word_lower = word.lower()
            if word_lower not in seen:
                seen.add(word_lower)
                unique_words.append(word_lower)
        
        return unique_words
    
    def recognize_region(self, x: int, y: int, width: int, height: int) -> List[str]:
        """è¯†åˆ«å±å¹•åŒºåŸŸä¸­çš„å•è¯
        
        Args:
            x: åŒºåŸŸå·¦ä¸Šè§’ X åæ ‡
            y: åŒºåŸŸå·¦ä¸Šè§’ Y åæ ‡
            width: åŒºåŸŸå®½åº¦
            height: åŒºåŸŸé«˜åº¦
        
        Returns:
            è¯†åˆ«å‡ºçš„å•è¯åˆ—è¡¨
        """
        # æˆªå–å±å¹•
        image = self.capture_region(x, y, width, height)
        
        # å±å¹•æœªå˜åŒ–åˆ™è·³è¿‡ OCR
        try:
            current_hash = self._compute_ahash(image)
            if self._last_image_hash is not None:
                diff = self._hamming_distance(self._last_image_hash, current_hash)
                if diff <= getattr(config, 'IMAGE_HASH_DIFF_THRESHOLD', 2):
                    if getattr(config, 'DEBUG', False):
                        print(f"ğŸ§© å›¾åƒæœªå˜åŒ–(H={diff})ï¼Œè·³è¿‡ OCR")
                    return []
            self._last_image_hash = current_hash
        except Exception:
            pass
        
        # è¯†åˆ«æ–‡å­—
        text = self.recognize_text(image)
        
        # æå–å•è¯
        words = self.extract_words(text)
        
        return words
    
    def get_primary_word(self, words: List[str]) -> Optional[str]:
        """ä»å•è¯åˆ—è¡¨ä¸­è·å–ä¸»è¦å•è¯ï¼ˆé€šå¸¸æ˜¯æœ€é•¿çš„ï¼‰
        
        Args:
            words: å•è¯åˆ—è¡¨
        
        Returns:
            ä¸»è¦å•è¯ï¼Œå¦‚æœåˆ—è¡¨ä¸ºç©ºè¿”å› None
        """
        if not words:
            return None
        
        # è¿”å›æœ€é•¿çš„å•è¯ï¼ˆé€šå¸¸èƒŒå•è¯è½¯ä»¶ä¼šçªå‡ºæ˜¾ç¤ºä¸»å•è¯ï¼‰
        return max(words, key=len)
    
    def should_update(self, word: Optional[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°æ˜¾ç¤ºï¼ˆé˜²æŠ–ï¼‰
        
        Args:
            word: å½“å‰è¯†åˆ«çš„å•è¯
        
        Returns:
            æ˜¯å¦éœ€è¦æ›´æ–°
        """
        if word is None:
            return False
        
        # å¦‚æœå’Œä¸Šæ¬¡è¯†åˆ«çš„å•è¯ä¸åŒï¼Œéœ€è¦æ›´æ–°
        if word != self.last_recognized_word:
            self.last_recognized_word = word
            return True
        
        return False


def main():
    """æµ‹è¯•ä»£ç """
    import time
    
    print("OCR å¼•æ“æµ‹è¯•")
    print("="*80)
    
    # æç¤ºç”¨æˆ·å‡†å¤‡æµ‹è¯•æ–‡æœ¬
    print("\nè¯·å‡†å¤‡ä¸€ä¸ªæ˜¾ç¤ºè‹±æ–‡å•è¯çš„çª—å£")
    print("ç¨‹åºå°†åœ¨ 5 ç§’åæˆªå–å±å¹•ä¸­å¿ƒ 300x100 çš„åŒºåŸŸè¿›è¡Œè¯†åˆ«...")
    
    for i in range(5, 0, -1):
        print(f"{i}...", end=' ', flush=True)
        time.sleep(1)
    print("\n")
    
    # åˆ›å»º OCR å¼•æ“
    ocr = OCREngine()
    
    # è·å–å±å¹•ä¸­å¿ƒåŒºåŸŸ
    from PIL import ImageGrab
    screen = ImageGrab.grab()
    screen_width, screen_height = screen.size
    
    # æˆªå–ä¸­å¿ƒåŒºåŸŸ
    x = screen_width // 2 - 150
    y = screen_height // 2 - 50
    width = 300
    height = 100
    
    print(f"æˆªå–åŒºåŸŸ: x={x}, y={y}, width={width}, height={height}")
    
    # è¯†åˆ«
    words = ocr.recognize_region(x, y, width, height)
    
    print(f"\nè¯†åˆ«ç»“æœ:")
    if words:
        print(f"  æ‰¾åˆ° {len(words)} ä¸ªå•è¯: {', '.join(words)}")
        primary = ocr.get_primary_word(words)
        print(f"  ä¸»è¦å•è¯: {primary}")
    else:
        print("  æœªè¯†åˆ«åˆ°å•è¯")
    
    print(f"\nè¯†åˆ«æ¬¡æ•°: {ocr.recognition_count}")


if __name__ == '__main__':
    main()

